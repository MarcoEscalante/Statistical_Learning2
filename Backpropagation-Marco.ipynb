{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UNIVERSIDAD GALILEO\n",
    "\n",
    "SL II\n",
    "\n",
    "Marco Vinicio Escalante Lara\n",
    "\n",
    "Carné: **19001148**\n",
    "\n",
    "\n",
    "# Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definimos nuestro set de entrenamiento y parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Las posibles combinaciones de xor\n",
    "x_entreno = np.array([[0., 0.], [0., 1.], [1., 0.], [1., 1.]]).T\n",
    "y_entreno = np.array([0., 1., 1., 0.]).reshape(-1, 1).T\n",
    "\n",
    "# Parametros inicializados aleatoriamente\n",
    "capa1 = np.random.normal(scale=0.2, size=(3, 3))\n",
    "capa2 = np.random.normal(scale=0.2, size=(2, 4))\n",
    "salida = np.random.normal(scale=0.2, size=(1, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definimos nuestra función de costos (MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_costo(x, y, capa1, capa2, salida):\n",
    "    # Tamaño de muestra a usar\n",
    "    size = x.T.shape[0]\n",
    "    # Calculamos el error, por lo que debemos calcular la salida de nuestra función y restar con el dato real\n",
    "    c_1 = np.matmul(capa1, np.vstack((np.ones(x.shape[1]), x)))\n",
    "    n_1 = np.maximum(c_1, 0.)\n",
    "    c_2 = np.matmul(capa2, np.vstack((np.ones(n_1.shape[1]), n_1)))\n",
    "    n_2 = np.maximum(c_2, 0.)\n",
    "    s_1 = np.matmul(salida, np.vstack((np.ones(n_2.shape[1]), n_2)))\n",
    "    # Calulo del error, entre lo real y lo calculado\n",
    "    dif = s_1.T - y.T\n",
    "    \n",
    "    # Determinamos la funcion de costos\n",
    "    Costo = 0.5*np.mean(np.power(dif, 2))\n",
    "    \n",
    "    # Iniciamos los gradiantes en un valor igual a cero para que se vayan computando \n",
    "    g1 = np.zeros_like(capa1)\n",
    "    g2 = np.zeros_like(capa2)\n",
    "    g3 = np.zeros_like(salida)\n",
    "    \n",
    "    c = x.T\n",
    "    d = y.T\n",
    "    yi = 0.\n",
    "    # Calculamos el Backpropagation en cada uno de los valores que tenemos\n",
    "    for i in range(size):\n",
    "        xi = c[i, :].reshape(-1, 1)\n",
    "        yi = d[i].reshape(-1,1)\n",
    "        # Definimos el forward propagation para poder determinar el error\n",
    "        n1 = np.vstack((np.ones(xi.shape[1]), xi))\n",
    "        c1 = np.matmul(capa1, n1)\n",
    "        n2 = np.maximum(c1, 0.)\n",
    "        n2 = np.vstack((np.ones(n2.shape[1]), n2))\n",
    "        c2 = np.matmul(capa2, n2)\n",
    "        n3 = np.maximum(c2, 0.)\n",
    "        n3 = np.vstack((np.ones(n3.shape[1]), n3))\n",
    "        s1 = np.matmul(salida, n3)\n",
    "        # Determinas el error en cada una de las capas\n",
    "        error_s = s1 - yi\n",
    "        error_2 = np.matmul(salida.T[1:], error_s) #* (s1 > 0).astype(np.float)\n",
    "        error_1 = np.matmul(capa2.T[1:, :], error_2) \n",
    "        \n",
    "        # Recalculamos los gradientes en base a los valores obtenidos\n",
    "        g3 += np.matmul(error_s, n3.T)\n",
    "        g2 += np.matmul(error_2, n2.T)\n",
    "        g1 += np.matmul(error_1, n1.T)\n",
    "\n",
    "    \n",
    "    capa1_grad = g1/size\n",
    "    capa2_grad = g2/size\n",
    "    salida_grad = g3/size\n",
    "\n",
    "    return Costo, capa1_grad, capa2_grad, salida_grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.15620944942423262, array([[ 0.01362129,  0.00679317,  0.00680082],\n",
       "        [-0.00618319, -0.00308366, -0.00308713],\n",
       "        [-0.00422718, -0.00210817, -0.00211054]]), array([[0.01763162, 0.0030073 , 0.00649473, 0.        ],\n",
       "        [0.03586667, 0.00611753, 0.01321173, 0.        ]]), array([[-0.24983666, -0.04434773,  0.        ]]))"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_costo(x_entreno, y_entreno, capa1, capa2, salida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def red_entreno(x, y, capa1, capa2, salida, rep, lr, mostrar):\n",
    "    \n",
    "    # Repetir hasta la iteracion puesta\n",
    "    for a in range(1, rep+1):\n",
    "        costo, capa1_g, capa2_g, salida_g = f_costo(x, y, capa1, capa2, salida)\n",
    "        # Mostrar los resultados divisibles entre los datos a mostrar\n",
    "        if (a % mostrar == 0):\n",
    "            print(\"Iteración: %d\" % a) \n",
    "            print(\"Costo: %f\" %  costo)\n",
    "        \n",
    "        # Actualizar los pesos sinápticos\n",
    "        capa1 += -lr * capa1_g\n",
    "        capa2 += -lr * capa2_g\n",
    "        salida += -lr * salida_g\n",
    "\n",
    "    return capa1, capa2, salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteración: 50\n",
      "Costo: 0.177633\n",
      "Iteración: 100\n",
      "Costo: 0.172419\n",
      "Iteración: 150\n",
      "Costo: 0.167726\n",
      "Iteración: 200\n",
      "Costo: 0.163502\n",
      "Iteración: 250\n",
      "Costo: 0.159699\n",
      "Iteración: 300\n",
      "Costo: 0.156274\n"
     ]
    }
   ],
   "source": [
    "capa1_entr, capa2_entr, salida_entr = red_entreno(x_entreno, y_entreno, capa1, capa2, salida, 300, 0.001, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grafica de salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f7ae4a89610>"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "c_1 = np.matmul(capa1_entr, np.vstack((np.ones(x_entreno.shape[1]), x_entreno)))\n",
    "n_1 = np.maximum(c_1, 0.)\n",
    "c_2 = np.matmul(capa2_entr, np.vstack((np.ones(n_1.shape[1]), n_1)))\n",
    "n_2 = np.maximum(c_2, 0.)\n",
    "s_1 = np.matmul(salida_entr, np.vstack((np.ones(n_2.shape[1]), n_2)))\n",
    "    \n",
    "x1 = x_entreno[0]\n",
    "x2 = x_entreno[1]\n",
    "plt.subplot(1,3,1)\n",
    "f = np.abs(s_1[0].T-1) < 0.5\n",
    "nf = np.logical_not(f)\n",
    "plt.scatter(x1[f.T], x2[f.T], color='b')\n",
    "plt.scatter(x1[nf.T], x2[nf.T], color='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONCLUSIONES\n",
    "\n",
    "No se puede apreciar el cambio esperado con el operador logico xor, sino que solo muestra un tipo de salida, cuando lo adecuado hubiera sido mostrar todos los posibles resultados correctos, tal vez podría deberse a como trabajamos las funciones de activación o que al final no requeriera una función de activación."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
